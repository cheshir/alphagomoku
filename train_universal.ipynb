{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaGomoku Training - Universal Notebook\n",
    "\n",
    "Works on:\n",
    "- ✓ Google Colab\n",
    "- ✓ Vast.ai\n",
    "- ✓ RunPod\n",
    "- ✓ Lambda Labs\n",
    "- ✓ AWS/GCP/Azure VMs\n",
    "- ✓ Local Jupyter\n",
    "\n",
    "**Model:** 18 blocks × 192 channels = 5.2M params\n",
    "\n",
    "**Recommended:** RTX 4090 (24GB) or A100 (40GB) with 64GB RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "# Detect environment\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "IS_KAGGLE = 'kaggle' in os.environ.get('KAGGLE_URL_BASE', '')\n",
    "\n",
    "print(f\"Platform: {platform.system()}\")\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Environment: {'Colab' if IS_COLAB else 'Kaggle' if IS_KAGGLE else 'Standard VM/Local'}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"GPU Memory: {gpu_memory_gb:.1f} GB\")\n",
    "    \n",
    "    # Recommend batch size\n",
    "    if gpu_memory_gb >= 32:\n",
    "        print(\"✓ Recommended batch size: 2048\")\n",
    "    elif gpu_memory_gb >= 20:\n",
    "        print(\"✓ Recommended batch size: 1024\")\n",
    "    elif gpu_memory_gb >= 12:\n",
    "        print(\"✓ Recommended batch size: 512\")\n",
    "    else:\n",
    "        print(\"⚠️  GPU has limited memory, will use checkpointing\")\n",
    "else:\n",
    "    print(\"❌ No GPU detected! Training will be very slow.\")\n",
    "    print(\"   For Colab: Runtime → Change runtime type → GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup Storage (Platform-specific)\n",
    "\n",
    "Choose the appropriate cell based on your platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GOOGLE COLAB ONLY ===\n",
    "# Uncomment and run if using Colab\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# PROJECT_DIR = '/content/drive/MyDrive/alphagomoku'\n",
    "# WORK_DIR = '/content/alphagomoku'\n",
    "# os.makedirs(PROJECT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === VAST.AI / RUNPOD / OTHER VMs ===\n",
    "# Use local storage (usually faster than network storage)\n",
    "\n",
    "PROJECT_DIR = os.path.expanduser('~/alphagomoku')\n",
    "WORK_DIR = PROJECT_DIR\n",
    "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Project directory: {PROJECT_DIR}\")\n",
    "print(f\"Working directory: {WORK_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get Code\n",
    "\n",
    "Choose one method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 1: Clone from Git\n",
    "!git clone https://github.com/YOUR_USERNAME/alphagomoku.git {WORK_DIR}\n",
    "%cd {WORK_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 2: If code already exists (Vast.ai with persistent storage)\n",
    "# Just navigate to it\n",
    "%cd {WORK_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 3: Upload code manually (for small updates)\n",
    "# Uncomment if needed\n",
    "\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()  # Upload zip file\n",
    "# !unzip -o alphagomoku.zip -d {WORK_DIR}\n",
    "# %cd {WORK_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if dependencies are already installed\n",
    "try:\n",
    "    import lmdb\n",
    "    import psutil\n",
    "    print(\"✓ Dependencies already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing dependencies...\")\n",
    "    !pip install -q numpy tqdm matplotlib lmdb psutil\n",
    "    print(\"✓ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "CONFIG = {\n",
    "    'epochs': 200,\n",
    "    'selfplay_games': 200,\n",
    "    'mcts_simulations': 150,\n",
    "    'parallel_workers': 4,\n",
    "    'lr': 1e-3,\n",
    "    'min_lr': 5e-4,\n",
    "    'difficulty': 'medium',\n",
    "    \n",
    "    # Paths\n",
    "    'checkpoint_dir': f'{PROJECT_DIR}/checkpoints',\n",
    "    'data_dir': f'{PROJECT_DIR}/data',\n",
    "    \n",
    "    # Device auto-configured\n",
    "    'device': 'auto',\n",
    "}\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(CONFIG['checkpoint_dir'], exist_ok=True)\n",
    "os.makedirs(CONFIG['data_dir'], exist_ok=True)\n",
    "\n",
    "print(\"\\nConfiguration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n✓ Ready to train!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Start Training\n",
    "\n",
    "**Auto-configuration:**\n",
    "- Model: 18 blocks × 192 channels (5.2M params)\n",
    "- Batch size: Auto-configured based on GPU\n",
    "- Checkpointing: Auto-enabled if needed\n",
    "\n",
    "**Training will:**\n",
    "- Save checkpoints every epoch\n",
    "- Auto-resume from latest checkpoint\n",
    "- Show progress in real-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "!python scripts/train.py \\\n",
    "    --epochs {CONFIG['epochs']} \\\n",
    "    --selfplay-games {CONFIG['selfplay_games']} \\\n",
    "    --mcts-simulations {CONFIG['mcts_simulations']} \\\n",
    "    --parallel-workers {CONFIG['parallel_workers']} \\\n",
    "    --lr {CONFIG['lr']} \\\n",
    "    --min-lr {CONFIG['min_lr']} \\\n",
    "    --warmup-epochs 0 \\\n",
    "    --lr-schedule cosine \\\n",
    "    --difficulty {CONFIG['difficulty']} \\\n",
    "    --checkpoint-dir {CONFIG['checkpoint_dir']} \\\n",
    "    --data-dir {CONFIG['data_dir']} \\\n",
    "    --device {CONFIG['device']} \\\n",
    "    --resume auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Monitor Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics_path = f\"{CONFIG['checkpoint_dir']}/training_metrics.csv\"\n",
    "\n",
    "if os.path.exists(metrics_path):\n",
    "    df = pd.read_csv(metrics_path)\n",
    "    \n",
    "    # Plot metrics\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    df.plot(x='epoch', y='loss', ax=axes[0,0], title='Training Loss', grid=True)\n",
    "    df.plot(x='epoch', y='policy_acc', ax=axes[0,1], title='Policy Accuracy', grid=True)\n",
    "    df.plot(x='epoch', y='value_mae', ax=axes[1,0], title='Value MAE', grid=True)\n",
    "    df.plot(x='epoch', y='lr', ax=axes[1,1], title='Learning Rate', grid=True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nTraining Progress: {len(df)}/200 epochs\")\n",
    "    print(f\"\\nLatest metrics (last 5 epochs):\")\n",
    "    print(df.tail())\n",
    "    \n",
    "    # Estimate time remaining\n",
    "    if 'epoch_time' in df.columns and len(df) > 0:\n",
    "        avg_time = df['epoch_time'].mean()\n",
    "        remaining_epochs = 200 - len(df)\n",
    "        remaining_hours = (avg_time * remaining_epochs) / 3600\n",
    "        print(f\"\\n⏱️  Estimated time remaining: {remaining_hours:.1f} hours\")\n",
    "else:\n",
    "    print(\"No metrics file found yet. Training hasn't started.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Check Latest Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# List all checkpoints\n",
    "checkpoints = sorted(glob.glob(f\"{CONFIG['checkpoint_dir']}/model_epoch_*.pt\"))\n",
    "\n",
    "if checkpoints:\n",
    "    print(f\"Found {len(checkpoints)} checkpoints:\\n\")\n",
    "    \n",
    "    # Show last 5\n",
    "    for cp in checkpoints[-5:]:\n",
    "        size_mb = os.path.getsize(cp) / 1024**2\n",
    "        epoch = cp.split('_')[-1].replace('.pt', '')\n",
    "        print(f\"  Epoch {epoch:>3}: {size_mb:>6.1f} MB - {os.path.basename(cp)}\")\n",
    "    \n",
    "    latest = checkpoints[-1]\n",
    "    print(f\"\\n✓ Latest checkpoint: {os.path.basename(latest)}\")\n",
    "else:\n",
    "    print(\"No checkpoints found yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Download Checkpoint (Optional)\n",
    "\n",
    "For Colab/Kaggle, download to local machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only works in Colab\n",
    "if IS_COLAB:\n",
    "    from google.colab import files\n",
    "    \n",
    "    checkpoints = sorted(glob.glob(f\"{CONFIG['checkpoint_dir']}/model_epoch_*.pt\"))\n",
    "    if checkpoints:\n",
    "        latest = checkpoints[-1]\n",
    "        print(f\"Downloading: {os.path.basename(latest)}\")\n",
    "        files.download(latest)\n",
    "    else:\n",
    "        print(\"No checkpoints to download\")\n",
    "else:\n",
    "    print(\"Download not needed - checkpoints are already on VM storage\")\n",
    "    print(f\"Checkpoint location: {CONFIG['checkpoint_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips by Platform\n",
    "\n",
    "### Google Colab\n",
    "- ✓ Sessions timeout after 12-24 hours\n",
    "- ✓ Checkpoints saved to Google Drive persist\n",
    "- ✓ Just re-run training cell to resume\n",
    "- ✓ Use Colab Pro for A100 access\n",
    "\n",
    "### Vast.ai\n",
    "- ✓ Hourly billing - pause anytime\n",
    "- ✓ Use persistent storage for checkpoints\n",
    "- ✓ Can rent spot instances (cheaper)\n",
    "- ⚠️ Spot instances can be interrupted\n",
    "\n",
    "### RunPod / Lambda Labs\n",
    "- ✓ More reliable than spot instances\n",
    "- ✓ Good for long training runs\n",
    "- ✓ Usually have persistent storage\n",
    "\n",
    "### Local / AWS / GCP\n",
    "- ✓ Full control over environment\n",
    "- ✓ Can run indefinitely\n",
    "- ✓ May need to install dependencies\n",
    "\n",
    "## Expected Training Time (200 epochs)\n",
    "\n",
    "| GPU | VRAM | Batch | Time/Epoch | Total |\n",
    "|-----|------|-------|-----------|-------|\n",
    "| RTX 4090 | 24GB | 1024 | ~2.5h | ~21 days |\n",
    "| A100 | 40GB | 2048 | ~1.8h | ~15 days |\n",
    "| V100 | 16GB | 1024 | ~3.5h | ~29 days |\n",
    "| RTX 3080 | 12GB | 512 | ~6h | ~50 days |\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "**Out of Memory:**\n",
    "- Script should auto-configure, but if OOM still happens:\n",
    "- Reduce workers: `--parallel-workers 2`\n",
    "- Reduce games: `--selfplay-games 100`\n",
    "\n",
    "**Slow Training:**\n",
    "- Check GPU is being used (should see CUDA in logs)\n",
    "- Reduce simulations if needed: `--mcts-simulations 100`\n",
    "\n",
    "**Connection Lost (Colab/Vast.ai):**\n",
    "- Just re-run training cell with `--resume auto`\n",
    "- Checkpoints saved every epoch\n",
    "\n",
    "**Code Updates:**\n",
    "- Re-clone repository or pull latest changes\n",
    "- Training will resume from latest checkpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
