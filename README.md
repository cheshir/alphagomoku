# AlphaGomoku: AlphaZero-style Gomoku AI

A strong Gomoku (15Ã—15) AI implementation using AlphaZero methodology with self-play training, Monte Carlo Tree Search (MCTS), and deep neural networks. **Now with evaluation framework and optimized training!** ğŸš€

## ğŸ¯ Project Overview

- **Goal**: Build a competitive Gomoku AI that can beat experienced human players
- **Architecture**: DW-ResNet-SE + MCTS + Threat-Space Search + Endgame Solver
- **Training**: Optimized for fast iteration with evaluation tracking
- **UI**: Modern Vue 3 web application with FastAPI backend
- **Deployment**: Docker + Docker Compose for easy setup
- **Board Size**: 15Ã—15 (classic Gomoku rules)

## ğŸ® Play Against Your AI

**Quick Start**:
```bash
docker-compose up --build
```

Then open http://localhost:5173 in your browser!

See [docs/QUICKSTART.md](docs/QUICKSTART.md) for detailed instructions.

## ğŸš€ Quick Start (Training)

### Prerequisites

- Python 3.8+
- PyTorch with MPS (Apple Silicon) or CUDA (NVIDIA GPU)
- 8GB+ RAM (16GB+ recommended)
- 20GB+ disk space

### Installation

```bash
# 1. Clone repository
git clone <repository-url>
cd alphagomoku

# 2. Create environment
conda create -n alphagomoku python=3.12
conda activate alphagomoku

# 3. Install dependencies
pip install -r requirements.txt
pip install -e .

# 4. Verify installation
make test
```

### Start Training

**NEW: Get recommendations for YOUR hardware!**
```bash
# See what's optimal for your hardware
make show-hardware-config
```

Or use preset configurations:

```bash
# Recommended: Fast iteration with evaluation
make train-fast

# Or: Balanced training (default)
make train

# Or: Maximum strength (slower)
make train-production
```

That's it! Training will:
- Use optimal model size for your hardware
- Evaluate automatically every 5 epochs
- Track Elo ratings
- Save checkpoints
- Resume automatically if interrupted

## ğŸ“Š Model Presets

Choose the right model for your needs:

| Preset | Parameters | Training Speed | Strength | Use Case |
|--------|-----------|---------------|----------|----------|
| **small** | 1.2M | âš¡âš¡âš¡ Fast | 80% | Development, experiments |
| **medium** | 3M | âš¡âš¡ Medium | 90% | Production, strong play |
| **large** | 5M | âš¡ Slow | 100% | Research, maximum strength |

**Recommendation**: Start with `small` for fast iteration, then scale to `medium` for production.

## ğŸ‹ï¸ Training Configurations

### Fast Iteration (Recommended for Development)
```bash
make train-fast
```
- Model: small (1.2M params)
- Time: 10-15 min/epoch
- Throughput: 80+ epochs/day
- Best for: Quick experiments, development

### Balanced Training (Recommended Default)
```bash
make train
```
- Model: small (1.2M params)
- Time: 15-25 min/epoch
- Throughput: 50+ epochs/day
- Best for: Achieving strong play quickly

### Production Training (Maximum Strength)
```bash
make train-production
```
- Model: medium (3M params)
- Time: 40-60 min/epoch
- Throughput: 24-36 epochs/day
- Best for: Final strong model

## ğŸ“ˆ Evaluation & Monitoring

Training automatically includes:

1. **Elo Rating Tracking**
   - Tracks model strength over epochs
   - Saved to `checkpoints/elo_history.json`

2. **Tactical Test Suite**
   - Tests win-in-1, defense, double attacks
   - Measures tactical awareness

3. **Win Rate vs Baseline**
   - Compares against fixed MCTS opponent
   - Shows if model is improving

View results:
```bash
# Evaluate latest checkpoint
make evaluate-latest

# Test tactical awareness
make test-tactical-latest

# View Elo history
cat checkpoints/elo_history.json
```

## ğŸ¨ Web UI Features

The project includes a complete web interface:

- **Modern Wood-Themed Board**: SVG-rendered 15Ã—15 Gomoku board
- **Three Difficulty Levels**: Easy, Medium, Hard
- **Real-Time Timers**: Track player and AI time
- **AI Thinking Indicator**: Visual feedback during AI computation
- **Debug Panel**: MCTS statistics, policy heatmap, top moves
- **Game Controls**: New game, resign, difficulty selection

See [docs/UI_IMPLEMENTATION.md](docs/UI_IMPLEMENTATION.md) for details.

## ğŸ“ Project Structure

```
alphagomoku/
â”œâ”€â”€ alphagomoku/          # Core ML package
â”‚   â”œâ”€â”€ config.py         # â­ NEW: Centralized configuration
â”‚   â”œâ”€â”€ env/              # Gomoku environment
â”‚   â”œâ”€â”€ model/            # Neural network (with presets!)
â”‚   â”œâ”€â”€ mcts/             # Monte Carlo Tree Search
â”‚   â”œâ”€â”€ tss/              # Threat-Space Search
â”‚   â”œâ”€â”€ endgame/          # Endgame solver
â”‚   â”œâ”€â”€ selfplay/         # Self-play data generation
â”‚   â”œâ”€â”€ train/            # Training pipeline (optimized!)
â”‚   â”œâ”€â”€ eval/             # â­ NEW: Evaluation framework
â”‚   â””â”€â”€ utils/            # Utilities
â”œâ”€â”€ apps/                 # Web application
â”‚   â”œâ”€â”€ backend/          # FastAPI server
â”‚   â””â”€â”€ frontend/         # Vue 3 UI
â”œâ”€â”€ scripts/              # Training scripts
â”œâ”€â”€ tests/                # Unit, integration tests
â”œâ”€â”€ docs/                 # Documentation
â”œâ”€â”€ Makefile              # â­ NEW: Optimized training commands
â””â”€â”€ checkpoints/          # Model checkpoints

â­ = New/significantly updated in refactoring
```

## ğŸ”§ Advanced Usage

### Custom Training Configuration

```bash
# Override specific parameters
python scripts/train.py \
    --model-preset small \
    --mcts-simulations 500 \
    --selfplay-games 150 \
    --epochs 100 \
    --eval-frequency 10
```

### Using Config Presets in Code

```python
from alphagomoku.config import get_training_config, print_config_summary
from alphagomoku.model.network import GomokuNet

# Load preset
config = get_training_config("balanced")
print_config_summary(config)

# Create model
model = GomokuNet.from_preset("small")
print(f"Model: {model.get_model_size():,} params")
```

### Resume Training

```bash
# Automatically resumes from latest checkpoint
make train

# Or specify checkpoint
python scripts/train.py --resume checkpoints/model_epoch_50.pt
```

## ğŸ§ª Testing

```bash
# Run unit tests
make test

# Run all tests (including integration)
make test-all

# Test specific module
pytest tests/unit/test_model.py -v
```

## ğŸ“– Documentation

### Getting Started
- [WHATS_NEW.md](WHATS_NEW.md) - What changed in refactoring
- [docs/QUICKSTART.md](docs/QUICKSTART.md) - 5-minute quick start guide
- [REFACTORING_SUMMARY.md](REFACTORING_SUMMARY.md) - Technical details

### Training & Evaluation
- [docs/TRAINING_PHILOSOPHY.md](docs/TRAINING_PHILOSOPHY.md) - **â­ Training strategy (pure MCTS vs TSS)**
- [COLAB_TRAINING.md](COLAB_TRAINING.md) - Train on Google Colab
- [HARDWARE_AUTO_CONFIG.md](HARDWARE_AUTO_CONFIG.md) - Hardware optimization
- [docs/CLOUD_VM_RECOMMENDATIONS.md](docs/CLOUD_VM_RECOMMENDATIONS.md) - Cloud GPU recommendations
- `make help` - See all training commands

### Architecture & Design
- [docs/PROJECT_DESCRIPTION.md](docs/PROJECT_DESCRIPTION.md) - Original specification
- [docs/TSS.md](docs/TSS.md) - Threat-Space Search details
- [docs/OPTIMIZATIONS.md](docs/OPTIMIZATIONS.md) - Performance optimizations

### API & Deployment
- [docs/API.md](docs/API.md) - Backend API documentation
- [docs/DEPLOYMENT.md](docs/DEPLOYMENT.md) - Deployment guide
- [docs/UI_IMPLEMENTATION.md](docs/UI_IMPLEMENTATION.md) - Frontend details

## ğŸ“ Key Improvements (2025 Refactoring)

The project was refactored for optimal training performance:

### Before
- Model: 5M params (slow)
- Training: 3-4 hours/epoch
- Total time (200 epochs): 14-16 days
- Evaluation: None âŒ
- Configuration: Scattered, hardcoded

### After
- Model: 1.2M params (small preset)
- Training: 15-25 min/epoch
- Total time (200 epochs): 2.5-4 days
- Evaluation: Every 5 epochs âœ…
- Configuration: Centralized presets

**Result**: 4-6x faster training with continuous evaluation!

See [WHATS_NEW.md](WHATS_NEW.md) for complete details.

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Follow the existing code style
2. Write tests for new features
3. Update documentation
4. Run `make test` before submitting

See [docs/DEVELOPMENT.md](docs/DEVELOPMENT.md) for development setup.

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ™ Acknowledgments

- **AlphaZero** paper (Silver et al., 2017) for the core methodology
- **Gomoku** community for game rules and strategies
- **PyTorch** team for the excellent deep learning framework

## ğŸ“ Support & Questions

- **Issues**: Use GitHub issues for bugs and feature requests
- **Discussions**: Use GitHub discussions for questions
- **Documentation**: Check `docs/` folder and `make help`

---

**Ready to train?** Run `make help` for all options, or start with `make train-fast`!
